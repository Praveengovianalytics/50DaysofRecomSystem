{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day-7-Collabrative-Filtering-recommendation-systems.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDJKCVaVvBLAc9uMMRsyvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveengovianalytics/50DaysofRecomSystem/blob/main/Day_7_Collabrative_Filtering_recommendation_systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQAJSifg8idP"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Praveengovianalytics/50DaysofRecomSystem/blob/main/Day4_Content_based_filtering_RecSys.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fj7Dja_88_d"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5MXToa880pj"
      },
      "source": [
        "<a id='CBRS'></a>\n",
        "# Collabrative filtering Recommender System\n",
        "\n",
        "\n",
        "Let us understand this with an example. If person A likes 3 movies, say Interstellar, Inception and Predestination, and person B likes Inception, Predestination and The Prestige, then they have almost similar interests. We can say with some certainty that A should like The Prestige and B should like Interstellar. The collaborative filtering algorithm uses “User Behavior” for recommending items. This is one of the most commonly used algorithms in the industry as it is not dependent on any additional information. There are different types of collaborating filtering techniques and we shall look at them in detail below. \n",
        "\n",
        "\n",
        "### User-User collaborative filtering\n",
        "\n",
        "This algorithm first finds the similarity score between users. Based on this similarity score, it then picks out the most similar users and recommends products which these similar users have liked or bought previously.\n",
        "\n",
        "\n",
        "In terms of our movies example from earlier, this algorithm finds the similarity between each user based on the ratings they have previously given to different movies. The prediction of an item for a user u is calculated by computing the weighted sum of the user ratings given by other users to an item i.\n",
        "\n",
        "\n",
        "### Item-Item collaborative filtering\n",
        "\n",
        "In this algorithm, we compute the similarity between each pair of items.\n",
        "\n",
        "So in our case we will find the similarity between each movie pair and based on that, we will recommend similar movies which are liked by the users in the past. This algorithm works similar to user-user collaborative filtering with just a little change – instead of taking the weighted sum of ratings of “user-neighbors”, we take the weighted sum of ratings of “item-neighbors”. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW9vqM-Q9DEX"
      },
      "source": [
        "# Import necessary data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YimMUUmu9CYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f315b50-ed07-4a82-9ca7-bcfe521965fc"
      },
      "source": [
        "# Download datasets\n",
        "!wget https://datasets.towardsai.net/combined_data_4.txt\n",
        "!wget https://raw.githubusercontent.com/towardsai/tutorials/master/recommendation_system_tutorial/movie_titles.csv\n",
        "!wget https://raw.githubusercontent.com/towardsai/tutorials/master/recommendation_system_tutorial/new_features.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-17 16:10:08--  https://datasets.towardsai.net/combined_data_4.txt\n",
            "Resolving datasets.towardsai.net (datasets.towardsai.net)... 104.28.12.7, 104.28.13.7, 172.67.128.100, ...\n",
            "Connecting to datasets.towardsai.net (datasets.towardsai.net)|104.28.12.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://towardsai.net/pcombined_data_4.txt [following]\n",
            "--2020-11-17 16:10:09--  https://towardsai.net/pcombined_data_4.txt\n",
            "Resolving towardsai.net (towardsai.net)... 172.67.128.100, 104.28.12.7, 104.28.13.7, ...\n",
            "Connecting to towardsai.net (towardsai.net)|172.67.128.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2020-11-17 16:10:11 ERROR 404: Not Found.\n",
            "\n",
            "--2020-11-17 16:10:11--  https://raw.githubusercontent.com/towardsai/tutorials/master/recommendation_system_tutorial/movie_titles.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577547 (564K) [text/plain]\n",
            "Saving to: ‘movie_titles.csv.1’\n",
            "\n",
            "movie_titles.csv.1  100%[===================>] 564.01K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2020-11-17 16:10:11 (6.94 MB/s) - ‘movie_titles.csv.1’ saved [577547/577547]\n",
            "\n",
            "--2020-11-17 16:10:11--  https://raw.githubusercontent.com/towardsai/tutorials/master/recommendation_system_tutorial/new_features.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6328 (6.2K) [text/plain]\n",
            "Saving to: ‘new_features.csv.1’\n",
            "\n",
            "new_features.csv.1  100%[===================>]   6.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-11-17 16:10:11 (75.7 MB/s) - ‘new_features.csv.1’ saved [6328/6328]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kJQ0pEf8Thp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a5a0821-5409-42c3-8933-bdf0df5318ab"
      },
      "source": [
        "!pip install scikit-surprise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 3.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp36-cp36m-linux_x86_64.whl size=1670922 sha256=1471c4cfb238725f01e0baaf4e293b33f85316ccb29b283f1463396ea171b9fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sq_m5eH8f0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03d1d124-136e-4d15-c6f4-9318152ed6ee"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDHKurgF9QE8"
      },
      "source": [
        "#Common Utils \n",
        "from datetime import datetime\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Data processing packages \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Data Vizualisation packages\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Metrics \n",
        "from scipy import sparse\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Recommedation & ML packages \n",
        "import xgboost as xgb\n",
        "from surprise import Reader, Dataset\n",
        "from surprise import BaselineOnly\n",
        "from surprise import KNNBaseline\n",
        "from surprise import SVD\n",
        "from surprise import SVDpp\n",
        "from surprise.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_ASi_yE9QKh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-cmx9B19QH6"
      },
      "source": [
        "def load_data():\n",
        "    netflix_csv_file = open(\"netflix_rating.csv\", mode = \"w\")\n",
        "    rating_files = ['combined_data_4.txt'] \n",
        "    for file in rating_files:\n",
        "        with open(file) as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if line.endswith(\":\"):\n",
        "                    movie_id = line.replace(\":\", \"\")\n",
        "                else:\n",
        "                    row_data = []\n",
        "                    row_data = [item for item in line.split(\",\")]\n",
        "                    row_data.insert(0, movie_id)\n",
        "                    netflix_csv_file.write(\",\".join(row_data))  \n",
        "                    netflix_csv_file.write('\\n')\n",
        "                    \n",
        "    netflix_csv_file.close()\n",
        "\n",
        "    \n",
        "    df = pd.read_csv('netflix_rating.csv', sep=\",\", names = [\"movie_id\",\"customer_id\", \"rating\", \"date\"])\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxoJsfQh9QCK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "25eaa63c-0bad-450d-bb8a-0a0fed4ed73d"
      },
      "source": [
        "netflix_rating_df = pd.read_csv('netflix_rating.csv', sep=\",\", names = [\"movie_id\",\"customer_id\", \"rating\", \"date\"])\n",
        "netflix_rating_df\n",
        "netflix_rating_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie_id</th>\n",
              "      <th>customer_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [movie_id, customer_id, rating, date]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iZkN_nS-Om1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e56869d-a6e4-4d3f-af25-92b2d0c1bc79"
      },
      "source": [
        "!wc -l *.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 17770 movie_titles.csv\n",
            "     0 netflix_rating.csv\n",
            "    74 new_features.csv\n",
            " 17844 total\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQvcE0lX-P7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae63fc42-f562-499b-9e4e-cc2b38ce2aae"
      },
      "source": [
        "!wget https://datasets.towardsai.net/combined_data_4.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-17 16:16:58--  https://datasets.towardsai.net/combined_data_4.txt\n",
            "Resolving datasets.towardsai.net (datasets.towardsai.net)... 104.28.13.7, 104.28.12.7, 172.67.128.100, ...\n",
            "Connecting to datasets.towardsai.net (datasets.towardsai.net)|104.28.13.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://towardsai.net/pcombined_data_4.txt [following]\n",
            "--2020-11-17 16:16:59--  https://towardsai.net/pcombined_data_4.txt\n",
            "Resolving towardsai.net (towardsai.net)... 104.28.12.7, 104.28.13.7, 172.67.128.100, ...\n",
            "Connecting to towardsai.net (towardsai.net)|104.28.12.7|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2020-11-17 16:17:00 ERROR 404: Not Found.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}